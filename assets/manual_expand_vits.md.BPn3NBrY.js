import{_ as i,c as a,o as t,a3 as e}from"./chunks/framework.HwITzfHN.js";const c=JSON.parse('{"title":"🎙️ 拓展语音VITS使用","description":"","frontmatter":{},"headers":[],"relativePath":"manual/expand/vits.md","filePath":"manual/expand/vits.md","lastUpdated":1753344436000}'),l={name:"manual/expand/vits.md"};function n(h,s,p,o,k,r){return t(),a("div",null,s[0]||(s[0]=[e(`<h1 id="🎙️-拓展语音vits使用" tabindex="-1">🎙️ 拓展语音VITS使用 <a class="header-anchor" href="#🎙️-拓展语音vits使用" aria-label="Permalink to &quot;🎙️ 拓展语音VITS使用&quot;">​</a></h1><h3 id="基础语音功能使用" tabindex="-1">基础语音功能使用 <a class="header-anchor" href="#基础语音功能使用" aria-label="Permalink to &quot;基础语音功能使用&quot;">​</a></h3><ul><li>若要使用 <code>Vits</code> 语音功能，请下载链接程序<a href="https://github.com/Artrajz/vits-simple-api" target="_blank" rel="noreferrer">simple-vits-api</a>。</li><li>该项目实现了基于 <code>Vits</code> 的简单语音合成 API。如果你是核显只能下载CPU版本。如果有独显建议下载 GPU 版本，速度快。</li><li>程序默认监听 23456 语音端口，程序默认导入的模型是 <a href="https://github.com/Zao-chen/ZcChat" target="_blank" rel="noreferrer">ZcChat 地址</a> -&gt; 讨论区 -&gt; 角色示范（丛雨）-&gt; <a href="https://github.com/Zao-chen/zao-chen.github.io/releases/download/%E8%B5%84%E6%BA%90%E4%B8%8B%E8%BD%BD/YuzuSoft_Vits.zip" target="_blank" rel="noreferrer">YuzuSoft_Vits.zip</a></li><li>模型下载好之后将压缩包 <code>YuzuSoft_Vits.zip</code> 解压到 simple-vits-api 的/data/models 目录下，再双击根目录下的 <code>start.bat</code> 启动就 ok 了</li><li>如果需要使用其他角色声线，请在 <code>game_data/characters/角色名/settings.txt</code> 中修改 <code>speaker_id</code> 这个属性（0~6可选）</li></ul><div class="note custom-block github-alert"><p class="custom-block-title">NOTE</p><p></p><ol><li>视频演示中的灵灵，语音使用的是Style-Bert-Vits2，丛雨的vits模型还需要打磨暂未发布，可以先用Simple-Vits-API，效果差不多</li><li>视频中的音理，请在Discussions区下载人物包，语音请使用Style-Bert-Vits2</li><li>建议先使用Simple-Vits-API玩玩，国人开发下载方便，需要扩展再用Style-Bert-Vits2</li><li>经过反映，如果你的电脑是核显或者太久以前的电脑，单个语音可能要一分钟才能生成，而GPU可以1秒内生成，而且会有大量报错可能，核显用户大可能只能放弃语音功能了（哭哭）</li></ol></div><h3 id="视觉模型功能使用" tabindex="-1">视觉模型功能使用 <a class="header-anchor" href="#视觉模型功能使用" aria-label="Permalink to &quot;视觉模型功能使用&quot;">​</a></h3><ul><li>从通义千问或者其他拥有视觉感知的大模型网站中，获取API -&gt; <a href="https://bailian.console.aliyun.com/?tab=api#/api" target="_blank" rel="noreferrer">阿里云的相关视觉模型API获取网站</a></li><li>在设置或者根目录的 <code>.env</code> 文件中修改 <code>VD_API_KEY</code>（图像识别模型的 API Key） 、<code>VD_BASE_URL</code>（视觉模型的 API 访问地址）和 <code>VD_MODEL</code>（视觉模型的模型类型）参数，例如： <strong>假设你要使用 <a href="https://bailian.console.aliyun.com/?tab=model&amp;accounttraceid=bef5c4d0bc384ad294f43f844ed11cd9thwc#/model-market/detail/qwen2.5-vl-7b-instruct" target="_blank" rel="noreferrer">qwen2.5-vl-7b-instruct</a> 模型：</strong><ol><li><code>VD_API_KEY</code> 参数填写你自己的阿里云 API Key</li><li>查看 <code>VD_BASE_URL</code> 需要点击<a href="https://bailian.console.aliyun.com/?tab=model&amp;accounttraceid=bef5c4d0bc384ad294f43f844ed11cd9thwc#/model-market/detail/qwen2.5-vl-7b-instruct" target="_blank" rel="noreferrer">页面</a>右上角的 <code>查看API参考</code>，之后你会在页面右侧看到以下代码，其中的 <code>base_url</code> 变量值就是 <code>VD_BASE_URL</code> 的值：<div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> os</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI(</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=&quot;sk-xxx&quot;,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">os.getenv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;DASHSCOPE_API_KEY&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># VD_BASE_URL的值</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">completion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> client.chat.completions.create(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;qwen-vl-plus&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 此处以qwen-vl-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;image_url&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;image_url&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;url&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://dashscope.oss-cn-beijing.aliyuncs.com/images/dog_and_girl.jpeg&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;这是什么&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ]}]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(completion.model_dump_json())</span></span></code></pre></div></li><li><code>VD_MODEL</code> 参数是模型的名称，点击<a href="https://bailian.console.aliyun.com/?tab=model&amp;accounttraceid=bef5c4d0bc384ad294f43f844ed11cd9thwc#/model-market/detail/qwen2.5-vl-7b-instruct" target="_blank" rel="noreferrer">页面</a>上方模型名称右侧的复制图标即可获取模型名称</li></ol></li><li>阿里云 API 默认赠送额度，不需要充值， <em>而且对于这个项目肯定够用一辈子了</em> 。</li></ul><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>设定完毕后，可以通过在与AI对话的对话中，包含 <code>“看桌面”</code> 或者 <code>“看看我的桌面”</code> 来触发视觉感知，允许AI观察你的屏幕并做出回应</p></div><h3 id="扩展语音功能使用" tabindex="-1">扩展语音功能使用 <a class="header-anchor" href="#扩展语音功能使用" aria-label="Permalink to &quot;扩展语音功能使用&quot;">​</a></h3><blockquote><p>（Style-Bert-Vits2模型使用更好的音色，可自定义训练）</p></blockquote><ul><li>从下方相关链接中，下载Style-Bert-Vits2的 <a href="https://github.com/litagin02/Style-Bert-VITS2/releases" target="_blank" rel="noreferrer">Release</a> 的 <strong>最新版本</strong> ，解压</li><li>先决定这个软件（安装后12GB）的安装位置，然后启动里面的<code>Install-Style-Bert-VITS2.bat</code>文件（如果之后更改这个软件的位置会有Bug）</li><li>耐心等待很长时间后，这个软件会安装好。由于这个项目庞大，所以等待时间非常长</li><li>下载完毕后，在 <code>model_assests</code> 目录中，把下载好的Bert-Vits模型解压进去</li><li>打开程序的目录，里面有个 <code>server.bat</code> ，启动它即可使用</li></ul><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>要是想使用这个功能，需要在 <code>game_data/characters/&lt;角色名&gt;/settings.txt</code> 中设定 <code>model_name</code> 的参数为导入的模型的名字<br> 模型的名字可以通过启动<code>app.bat</code>中的人物列表中查看</p></div>`,11)]))}const E=i(l,[["render",n]]);export{c as __pageData,E as default};
