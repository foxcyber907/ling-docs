import{_ as a,c as e,o as s,ag as t}from"./chunks/framework.BHpayLOB.js";const l="/avatars/LingChat.png",g=JSON.parse('{"title":"🐈✨ LingChat - 灵动の人工智能聊天陪伴助手","description":"","frontmatter":{},"headers":[],"relativePath":"manual/index.md","filePath":"manual/index.md"}'),n={name:"manual/index.md"};function r(h,i,o,p,d,k){return s(),e("div",null,i[0]||(i[0]=[t('<h1 id="🐈✨-lingchat-灵动の人工智能聊天陪伴助手" tabindex="-1">🐈✨ LingChat - 灵动の人工智能聊天陪伴助手 <a class="header-anchor" href="#🐈✨-lingchat-灵动の人工智能聊天陪伴助手" aria-label="Permalink to &quot;🐈✨ LingChat - 灵动の人工智能聊天陪伴助手&quot;">​</a></h1><p><img src="'+l+`" alt="official"></p><h2 id="🖥️-支持操作系统" tabindex="-1">🖥️ 支持操作系统： <a class="header-anchor" href="#🖥️-支持操作系统" aria-label="Permalink to &quot;🖥️ 支持操作系统：&quot;">​</a></h2><ul><li>Windows、Linux均可运行。Linux用户请查看额外的使用说明。</li><li>安装问题解答文档<a href="https://github.com/SlimeBoyOwO/LingChat/blob/main/README-help.md" target="_blank" rel="noreferrer">用户帮助文档-代码报错</a>, <a href="https://github.com/SlimeBoyOwO/LingChat/blob/develop/others/document/Q&amp;A.md" target="_blank" rel="noreferrer">用户帮助文档-截图报错</a></li></ul><h2 id="🛠-功能列表" tabindex="-1">🛠 功能列表 <a class="header-anchor" href="#🛠-功能列表" aria-label="Permalink to &quot;🛠 功能列表&quot;">​</a></h2><ul><li>[x] 选择你喜欢的人物，陪伴你聊天度过寂寞的夜晚</li><li>[x] 内嵌永久记忆功能，优化和高自定义的RAG系统记录你们的一点一滴</li><li>[x] 使用自训练的AI情绪识别模型，自动判定AI的每次对话情绪</li><li>[x] 表情，动作，气泡随着AI的情绪改变，提供灵活的AI聊天体验</li><li>[x] 非RAG下有存档功能，用不同的方式攻略Galgame人物吧</li><li>[x] 搭配Vits语音服务或对话音效，用真实的耳语调动你的真心</li><li>[x] 支持自定义角色，可以用自己的oc或者游戏人物与自己对话</li><li>[x] 清爽的设置菜单，高度自定义的设置选项，可搭配不同背景和音乐聊天</li></ul><h2 id="⭐-快速上手" tabindex="-1">⭐ 快速上手 <a class="header-anchor" href="#⭐-快速上手" aria-label="Permalink to &quot;⭐ 快速上手&quot;">​</a></h2><h3 id="step-0-开始之前的准备" tabindex="-1">Step 0: 开始之前的准备 <a class="header-anchor" href="#step-0-开始之前的准备" aria-label="Permalink to &quot;Step 0: 开始之前的准备&quot;">​</a></h3><ul><li>在DeepSeek或者其他大模型网站中，申请自己的API密钥，并且保证有余额供使用 -&gt; <a href="https://platform.deepseek.com/" target="_blank" rel="noreferrer">DeepSeek的官方API获取网站</a></li></ul><h3 id="step-1-下载软件" tabindex="-1">Step 1: 下载软件 <a class="header-anchor" href="#step-1-下载软件" aria-label="Permalink to &quot;Step 1: 下载软件&quot;">​</a></h3><ul><li>在<a href="https://github.com/SlimeBoyOwO/LingChat/releases" target="_blank" rel="noreferrer">release</a>中，找到最新的版本，下载如 <code>LingChat.x.x.x.7z</code> 的文件，下载完成后解压它。</li><li>点击根目录下的 <code>LingChat.exe</code> 启动程序</li></ul><h4 id="温馨提示" tabindex="-1">温馨提示： <a class="header-anchor" href="#温馨提示" aria-label="Permalink to &quot;温馨提示：&quot;">​</a></h4><blockquote><p>解压完成后可能会发生 <code>LingChat.exe</code> 不见了的情况，这多半是由于 Windows Defender 把它当病毒干掉了。需要手动打开<strong>Windows安全中心</strong>，选择<strong>病毒和威胁防护</strong>一栏，允许该威胁。</p></blockquote><h3 id="step-2-首次启动配置" tabindex="-1">Step 2: 首次启动配置 <a class="header-anchor" href="#step-2-首次启动配置" aria-label="Permalink to &quot;Step 2: 首次启动配置&quot;">​</a></h3><ul><li>启动程序后，点开右上角的菜单，点击【文字】部分的【进入设置页面】按钮，输入自己选用的大模型类型和API，模型信息等（<strong>这些是必填信息</strong>）</li><li>设置完毕后，滑动到最下方，点击保存配置。关闭黑不溜秋的窗口和LingChat程序，重新点击 <code>LingChat.exe</code> 启动程序，就可以使用啦！</li></ul><div class="important custom-block github-alert"><p class="custom-block-title">IMPORTANT</p><p></p><ol><li><strong>有些用户的电脑启动<code>LingChat.exe</code>之后会无限卡在加载页，请在现代浏览器如谷歌中输入<code>localhost:8765</code>进入程序</strong></li><li><strong>当你关闭程序准备重启初始化时候，务必保证前端和后端都关闭（exe或者浏览器的网页，还有cmd窗口），否则可能出现进去人物消失的情况</strong></li></ol></div><h3 id="step-3-基础语音功能使用-从这里开始的以下步骤属于扩展功能-按需进行" tabindex="-1">Step 3：基础语音功能使用（从这里开始的以下步骤属于扩展功能，按需进行） <a class="header-anchor" href="#step-3-基础语音功能使用-从这里开始的以下步骤属于扩展功能-按需进行" aria-label="Permalink to &quot;Step 3：基础语音功能使用（从这里开始的以下步骤属于扩展功能，按需进行）&quot;">​</a></h3><ul><li>若要使用 <code>Vits</code> 语音功能，请下载链接程序<a href="https://github.com/Artrajz/vits-simple-api" target="_blank" rel="noreferrer">simple-vits-api</a>。</li><li>该项目实现了基于 <code>Vits</code> 的简单语音合成 API。如果你是核显只能下载CPU版本。如果有独显建议下载 GPU 版本，速度快。</li><li>程序默认监听 23456 语音端口，程序默认导入的模型是 <a href="https://github.com/Zao-chen/ZcChat" target="_blank" rel="noreferrer">ZcChat 地址</a> -&gt; 讨论区 -&gt; 角色示范（丛雨）-&gt; <a href="https://github.com/Zao-chen/zao-chen.github.io/releases/download/%E8%B5%84%E6%BA%90%E4%B8%8B%E8%BD%BD/YuzuSoft_Vits.zip" target="_blank" rel="noreferrer">YuzuSoft_Vits.zip</a></li><li>模型下载好之后将压缩包 <code>YuzuSoft_Vits.zip</code> 解压到 simple-vits-api 的/data/models 目录下，再双击根目录下的 <code>start.bat</code> 启动就 ok 了</li><li>如果需要使用其他角色声线，请在 <code>game_data/characters/角色名/settings.txt</code> 中修改 <code>speaker_id</code> 这个属性（0~6可选）</li></ul><div class="note custom-block github-alert"><p class="custom-block-title">NOTE</p><p></p><ol><li>视频演示中的灵灵，语音使用的是Style-Bert-Vits2，丛雨的vits模型还需要打磨暂未发布，可以先用Simple-Vits-API，效果差不多</li><li>视频中的音理，请在Discussions区下载人物包，语音请使用Style-Bert-Vits2</li><li>建议先使用Simple-Vits-API玩玩，国人开发下载方便，需要扩展再用Style-Bert-Vits2</li><li>经过反映，如果你的电脑是核显或者太久以前的电脑，单个语音可能要一分钟才能生成，而GPU可以1秒内生成，而且会有大量报错可能，核显用户大可能只能放弃语音功能了（哭哭）</li></ol></div><h3 id="step-4-视觉模型功能使用" tabindex="-1">Step 4：视觉模型功能使用 <a class="header-anchor" href="#step-4-视觉模型功能使用" aria-label="Permalink to &quot;Step 4：视觉模型功能使用&quot;">​</a></h3><ul><li>从通义千问或者其他拥有视觉感知的大模型网站中，获取API -&gt; <a href="https://bailian.console.aliyun.com/?tab=api#/api" target="_blank" rel="noreferrer">阿里云的相关视觉模型API获取网站</a></li><li>在设置或者根目录的 <code>.env</code> 文件中修改 <code>VD_API_KEY</code>（图像识别模型的 API Key） 、<code>VD_BASE_URL</code>（视觉模型的 API 访问地址）和 <code>VD_MODEL</code>（视觉模型的模型类型）参数，例如： <strong>假设你要使用 <a href="https://bailian.console.aliyun.com/?tab=model&amp;accounttraceid=bef5c4d0bc384ad294f43f844ed11cd9thwc#/model-market/detail/qwen2.5-vl-7b-instruct" target="_blank" rel="noreferrer">qwen2.5-vl-7b-instruct</a> 模型：</strong><ol><li><code>VD_API_KEY</code> 参数填写你自己的阿里云 API Key</li><li>查看 <code>VD_BASE_URL</code> 需要点击<a href="https://bailian.console.aliyun.com/?tab=model&amp;accounttraceid=bef5c4d0bc384ad294f43f844ed11cd9thwc#/model-market/detail/qwen2.5-vl-7b-instruct" target="_blank" rel="noreferrer">页面</a>右上角的 <code>查看API参考</code>，之后你会在页面右侧看到以下代码，其中的 <code>base_url</code> 变量值就是 <code>VD_BASE_URL</code> 的值：<div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> os</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI(</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=&quot;sk-xxx&quot;,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">os.getenv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;DASHSCOPE_API_KEY&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># VD_BASE_URL的值</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">completion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> client.chat.completions.create(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;qwen-vl-plus&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 此处以qwen-vl-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;image_url&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;image_url&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;url&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://dashscope.oss-cn-beijing.aliyuncs.com/images/dog_and_girl.jpeg&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;这是什么&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ]}]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(completion.model_dump_json())</span></span></code></pre></div></li><li><code>VD_MODEL</code> 参数是模型的名称，点击<a href="https://bailian.console.aliyun.com/?tab=model&amp;accounttraceid=bef5c4d0bc384ad294f43f844ed11cd9thwc#/model-market/detail/qwen2.5-vl-7b-instruct" target="_blank" rel="noreferrer">页面</a>上方模型名称右侧的复制图标即可获取模型名称</li></ol></li><li>阿里云 API 默认赠送额度，不需要充值， <em>而且对于这个项目肯定够用一辈子了</em> 。</li></ul><h4 id="温馨提示-1" tabindex="-1">温馨提示： <a class="header-anchor" href="#温馨提示-1" aria-label="Permalink to &quot;温馨提示：&quot;">​</a></h4><blockquote><p>设定完毕后，可以通过在与AI对话的对话中，包含 <code>“看桌面”</code> 或者 <code>“看看我的桌面”</code> 来触发视觉感知，允许AI观察你的屏幕并做出回应</p></blockquote><h3 id="step-5-扩展语音功能使用-style-bert-vits2模型使用-更好的音色-可自定义训练" tabindex="-1">Step 5: 扩展语音功能使用（Style-Bert-Vits2模型使用，更好的音色，可自定义训练） <a class="header-anchor" href="#step-5-扩展语音功能使用-style-bert-vits2模型使用-更好的音色-可自定义训练" aria-label="Permalink to &quot;Step 5: 扩展语音功能使用（Style-Bert-Vits2模型使用，更好的音色，可自定义训练）&quot;">​</a></h3><ul><li>从下方相关链接中，下载Style-Bert-Vits2的 <a href="https://github.com/litagin02/Style-Bert-VITS2/releases" target="_blank" rel="noreferrer">Release</a> 的 <strong>最新版本</strong> ，解压</li><li>先决定这个软件（安装后12GB）的安装位置，然后启动里面的<code>Install-Style-Bert-VITS2.bat</code>文件（如果之后更改这个软件的位置会有Bug）</li><li>耐心等待很长时间后，这个软件会安装好。由于这个项目庞大，所以等待时间非常长</li><li>下载完毕后，在 <code>model_assests</code> 目录中，把下载好的Bert-Vits模型解压进去</li><li>打开程序的目录，里面有个 <code>server.bat</code> ，启动它即可使用</li></ul><h4 id="温馨提示-2" tabindex="-1">温馨提示： <a class="header-anchor" href="#温馨提示-2" aria-label="Permalink to &quot;温馨提示：&quot;">​</a></h4><blockquote><p>要是想使用这个功能，需要在 <code>game_data/characters/&lt;角色名&gt;/settings.txt</code> 中设定 <code>model_name</code> 的参数为导入的模型的名字<br> 模型的名字可以通过启动<code>app.bat</code>中的人物列表中查看</p></blockquote><h3 id="step-6-加入最新版的测试" tabindex="-1">Step 6: 加入最新版的测试 <a class="header-anchor" href="#step-6-加入最新版的测试" aria-label="Permalink to &quot;Step 6: 加入最新版的测试&quot;">​</a></h3><ul><li>我们一直在更新LingChat，所有更新都会随时推送到<a href="https://github.com/SlimeBoyOwO/LingChat/tree/develop" target="_blank" rel="noreferrer">develop</a>中，我们也会在<a href="https://github.com/SlimeBoyOwO/LingChat/issues" target="_blank" rel="noreferrer">issues</a>中发布开发日志。</li><li>你可以参考<a href="https://github.com/SlimeBoyOwO/LingChat/blob/develop/others/document/%E6%BA%90%E4%BB%A3%E7%A0%81%E4%BD%BF%E7%94%A8.md" target="_blank" rel="noreferrer">源代码使用教程</a>来使用LingChat的源代码，并随时获取最新的develop开发版更新。</li><li>开发版是不稳定的版本，如果遇到任何Bug，欢迎向我们反馈！</li></ul><h2 id="🔗-相关-致谢链接" tabindex="-1">🔗 相关 &amp; 致谢链接 <a class="header-anchor" href="#🔗-相关-致谢链接" aria-label="Permalink to &quot;🔗 相关 &amp; 致谢链接&quot;">​</a></h2><ul><li><a href="https://github.com/Zao-chen/ZcChat" target="_blank" rel="noreferrer">Zcchat</a>: 本项目的灵感来源，可以在这里找到 <code>Vits</code> 模型和人物素材。可以的话也帮他们点个stars吧❤</li><li><a href="https://github.com/Artrajz/vits-simple-api" target="_blank" rel="noreferrer">Simple-Vits-API</a>: 该项目实现了基于 <code>VITS</code> 的简单语音合成 API。如果你不是核显建议下载 GPU 版本，速度快。核显就用CPU。</li><li><a href="https://github.com/litagin02/Style-Bert-VITS2" target="_blank" rel="noreferrer">Style-Bert-VITS2</a>：该项目实现了 <code>Bert-VITS</code> 的语音合成和训练，你可以用这个进行语音训练和推理，少量数据量就可以达到很棒效果！</li><li><a href="https://github.com/Aikoyori/ProgrammingVTuberLogos" target="_blank" rel="noreferrer">ProgrammingVTuberLogos</a>：LingChat 的标题风格，可爱滴捏，画风参考这个项目~</li><li><a href="https://github.com/SlimeBoyOwO/Emotion-Model-Trainer" target="_blank" rel="noreferrer">Emotion Training</a>: 人工智能模型训练，用于实现18种短句情绪识别</li><li>本项目的实现离不开这些优秀开源作品的先驱者，在这里我们送上由衷的致谢🌼</li></ul><h2 id="🌸-一些小话" tabindex="-1">🌸 一些小话 <a class="header-anchor" href="#🌸-一些小话" aria-label="Permalink to &quot;🌸 一些小话&quot;">​</a></h2><ul><li>本项目为了快速开发用了很多 AI 工具，有做的不好的地方欢迎指出！我们欢迎各位开发者或用户提出issues！</li><li>感谢一路结识的开发者，都是 <strong>香软可爱</strong> 又厉害的大佬们~ 如果你有开发意向可以联系我！开发者群号就藏在GitHub中❤</li><li>本项目更多作为一个超小型的学习项目，由于文件结构非常简单， <s>欢迎有兴趣的人学习</s> 。现在变大了，应用了很多软件工程的架构思想，也欢迎学习啦qwq</li></ul><h2 id="🔍-其他" tabindex="-1">🔍 其他 <a class="header-anchor" href="#🔍-其他" aria-label="Permalink to &quot;🔍 其他&quot;">​</a></h2><blockquote><p>本项目使用的气泡+音效素材来源于碧蓝档案，其中对话哔哔音效来源于Undertale，请勿商用<br> 默认简单狼狼立绘是自绘，表情差分源于 AI + 人工修改，如果你想自己创作可使用 NovelAI 网站或者自己画 请对AI生成的东西和使用负责，不要肆意传播不良信息 有其他问题可以提issues捏~</p></blockquote><h2 id="⭐️-星星" tabindex="-1">⭐️ 星星 <a class="header-anchor" href="#⭐️-星星" aria-label="Permalink to &quot;⭐️ 星星&quot;">​</a></h2><p><a href="https://www.star-history.com/#SlimeBoyOwO/LingChat&amp;Date" target="_blank" rel="noreferrer"><img src="https://api.star-history.com/svg?repos=SlimeBoyOwO/LingChat&amp;type=Date" alt="Star History Chart"></a></p><p>© LingChat 制作团队</p>`,38)]))}const u=a(n,[["render",r]]);export{g as __pageData,u as default};
